{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe8d1aa",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust ads library for 2.5.9 version\n",
    "!pip install -U oracle-ads==2.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c185c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all needed libraries\n",
    "import ads\n",
    "import json\n",
    "import logging\n",
    "import oci\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import tempfile\n",
    "import uuid\n",
    "import warnings\n",
    "from os import path\n",
    "\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model import ADSModel\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.model.framework.automl_model import AutoMLModel\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.dataset.label_encoder import DataFrameLabelEncoder\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from oci.data_science import models\n",
    "from ads.model.deployment import ModelDeployer, ModelDeploymentProperties\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('ads').setLevel(level=logging.ERROR)\n",
    "logging.getLogger('ADS').setLevel(level=logging.ERROR)\n",
    "logging.getLogger('ODSC-ModelDeployment').setLevel(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "URL=\"https://www2.cs.arizona.edu/classes/cs120/fall17/ASSIGNMENTS/assg02/Pokemon.csv\"\n",
    "ds = DatasetFactory.open(pd.read_csv(URL, header = 0)).set_target('Legendary')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c909fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the target columns is unbalanced\n",
    "ds.plot(\"Legendary\").show_in_notebook(figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71288bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the target feature using upsampling technique\n",
    "ds = ds.up_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the target is now balanced\n",
    "ds.plot(\"Legendary\").show_in_notebook(figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5459d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply one hot encondig to category features and drop \"#\" and \"name\" columns\n",
    "df = ds.to_pandas()\n",
    "data_t1 = ds.to_pandas()['Type_1']\n",
    "data_t2 = ds.to_pandas()['Type_2']\n",
    "\n",
    "onehot_t1 = pd.get_dummies(data_t1, prefix='Type_1', drop_first=True)\n",
    "onehot_t2 = pd.get_dummies(data_t2, prefix='Type_2', drop_first=True)\n",
    "\n",
    "df_ohe = df.merge(onehot_t1, right_index=True, left_index=True)\n",
    "df_ohe = df_ohe.merge(onehot_t2, right_index=True, left_index=True)\n",
    "df_ohe = df_ohe.drop(['#', 'Name', 'Type_1','Type_2'], axis=1)\n",
    "ds_ohe = DatasetFactory.open(df_ohe).set_target('Legendary')\n",
    "ds_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de645b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataframe into train and test\n",
    "train, test = ds_ohe.train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Oracle AutoMl engine to automatic adjust the model using Random Forest algorithm\n",
    "ml_engine = OracleAutoMLProvider(n_jobs=-1, loglevel=logging.ERROR)\n",
    "\n",
    "oracle_automl = AutoML(train, provider=ml_engine)\n",
    "model, baseline = oracle_automl.train(model_list=['RandomForestClassifier'], \n",
    "                                      random_state = 42, time_budget = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model using the first 10 data\n",
    "model.predict(test.X.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the model evaluating\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "evaluator = ADSEvaluator(test, models=[model], training_data=train)\n",
    "\n",
    "evaluator.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f364972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a directory to store the model artifact\n",
    "artifact_dir = '/home/datascience/Deeper Model Deployment Logs Analysis/Model'\n",
    "print(f\"Model artifact director: {artifact_dir}\")\n",
    "automl_model = AutoMLModel(estimator=model, artifact_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genarate the model artifact\n",
    "conda_env = 'generalml_p37_cpu_v1'\n",
    "\n",
    "automl_model.prepare(inference_conda_env=conda_env,\n",
    "                     training_conda_env=conda_env,\n",
    "                     use_case_type='binary_classification',\n",
    "                     X_sample=train.X,\n",
    "                     y_sample=train.y,\n",
    "                     force_overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the score.py content\n",
    "with open(path.join(artifact_dir, \"score.py\"), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the score.py content\n",
    "score = '''\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from cloudpickle import cloudpickle\n",
    "from functools import lru_cache\n",
    "import logging\n",
    "import sys\n",
    "import automl\n",
    "\n",
    "\n",
    "model_name = 'model.pkl'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Inference script. This script is used for prediction by scoring server when schema is known.\n",
    "\"\"\"\n",
    "\n",
    "def init_automl_logger():\n",
    "    logger = logging.getLogger(\"automl\")\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging.ERROR)\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    automl.init(engine=\"local\", engine_opts={\"n_jobs\": 1}, logger=logger)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=10)\n",
    "def load_model(model_file_name=model_name):\n",
    "    \"\"\"\n",
    "    Loads model from the serialized format\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model:  a model instance on which predict API can be invoked\n",
    "    \"\"\"\n",
    "    init_automl_logger()\n",
    "    model_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    if model_dir not in sys.path:\n",
    "        sys.path.insert(0, model_dir)\n",
    "    contents = os.listdir(model_dir)\n",
    "    if model_file_name in contents:\n",
    "        print(f'Start loading {model_file_name} from model directory {model_dir} ...')\n",
    "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), model_file_name), \"rb\") as file:\n",
    "            loaded_model = cloudpickle.load(file)\n",
    "\n",
    "        print(\"Model is successfully loaded.\")\n",
    "        return loaded_model\n",
    "    else:\n",
    "        raise Exception(f'{model_file_name} is not found in model directory {model_dir}')\n",
    "\n",
    "\n",
    "def pre_inference(data):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Data format as expected by the predict API of the core estimator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: Data format after any processing.\n",
    "\n",
    "    \"\"\"\n",
    "    return data\n",
    "\n",
    "def post_inference(yhat):\n",
    "    \"\"\"\n",
    "    Post-process the model results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yhat: Data format after calling model.predict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    yhat: Data format after any processing.\n",
    "\n",
    "    \"\"\"\n",
    "    return yhat.tolist()\n",
    "\n",
    "def predict(data, model=load_model()):\n",
    "    \"\"\"\n",
    "    Returns prediction given the model and data to predict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Model instance returned by load_model API\n",
    "    data: Data format as expected by the predict API of the core estimator. For eg. in case of sckit models it could be numpy array/List of list/Pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions: Output from scoring server\n",
    "        Format: {'prediction': output from model.predict method}\n",
    "\n",
    "    \"\"\"\n",
    "    from pandas import read_json, DataFrame\n",
    "    from io import StringIO\n",
    "    X = read_json(StringIO(data)) if isinstance(data, str) else DataFrame.from_dict(data)\n",
    "    features = pre_inference(X)\n",
    "    yhat = post_inference(\n",
    "        model.predict(features)\n",
    "    )\n",
    "    logging.info(yhat)\n",
    "    return {'prediction': yhat}\n",
    "'''\n",
    "with open(path.join(artifact_dir, \"score.py\"), 'w') as f:\n",
    "    f.write(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display model taxonomy\n",
    "automl_model.metadata_taxonomy.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d19952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the model status list\n",
    "automl_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090014b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the model prediction\n",
    "automl_model.verify(test.X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e110738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display model information\n",
    "automl_model.runtime_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50534d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model to the Model Catalog\n",
    "model_id = automl_model.save(display_name='Deeper Analysis using AutoML Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a log group to receive the model deployment logs\n",
    "from ads.common.oci_logging import OCILogGroup\n",
    "\n",
    "# Generate a random log group and log name\n",
    "log_group_name = \"ModelDeployment-Demo-\" + str(uuid.uuid4())\n",
    "access_log_name = \"ModelDeployment-Demo-Access_Log-\" + str(uuid.uuid4())\n",
    "predict_log_name = \"ModelDeployment-Demo-Predict_Log-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create a log group\n",
    "log_group = OCILogGroup(display_name=log_group_name).create()\n",
    "log_group_ocid = log_group.id\n",
    "print(f\"Log group OCID: {log_group_ocid}\")\n",
    "\n",
    "# Create an access log in the log group\n",
    "access_log = log_group.create_log(access_log_name)\n",
    "access_log_ocid = access_log.id\n",
    "print(f\"Access log OCID: {access_log_ocid}\")\n",
    "\n",
    "# Create a predict log in the log group\n",
    "predict_log = log_group.create_log(predict_log_name)\n",
    "predict_log_ocid = predict_log.id\n",
    "print(f\"Predict log OCID: {predict_log_ocid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cf773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#initialize ModelDeploymentProperties\n",
    "compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "project_id = os.environ['PROJECT_OCID']\n",
    "model_deployment_properties = ModelDeploymentProperties(\n",
    "    model_id\n",
    ").with_prop(\n",
    "    'display_name', \"Model Deployment Demo using ADS\"\n",
    ").with_prop(\n",
    "    \"project_id\", project_id\n",
    ").with_prop(\n",
    "    \"compartment_id\", compartment_id\n",
    ").with_logging_configuration(\n",
    "    log_group_ocid, access_log_ocid, log_group_ocid, predict_log_ocid\n",
    ").with_instance_configuration(\n",
    "    config={\"INSTANCE_SHAPE\":\"VM.Standard2.1\", \"INSTANCE_COUNT\":\"1\",'bandwidth_mbps':10}\n",
    ")\n",
    "\n",
    "#deploy the model\n",
    "deployer = ModelDeployer()\n",
    "deployment = deployer.deploy(\n",
    "    model_deployment_properties,\n",
    "    max_wait_time = 2700\n",
    ")\n",
    "\n",
    "deployment_id = deployment.model_deployment_id\n",
    "print(f\"Deployment {deployment_id} is {deployment.state.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model deployment\n",
    "deployment.predict(train.X[0:1].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657428dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a loop invocation to genarate logs\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "for i in range (0, 221, 1):\n",
    "    w = random.randrange(0, 60, 2)\n",
    "    try:\n",
    "        deployment.predict(test.X[i:i+1].to_json())\n",
    "        print('Model Deployment was invoke successfully.')\n",
    "    except ValueError as e:\n",
    "        print(f'Failed to invoke the Model Deployment with the following error: {e}')\n",
    "    sleep(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
